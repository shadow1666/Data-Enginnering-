{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Spark SQL \u2013 Overview\n", "\n", "Let us get an overview of Spark SQL.\n", "\n", "Here are the standard operations which we typically perform as part of processing the data. In Spark we can perform these using Data Frame APIs or **Spark SQL**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["* Selection or Projection \u2013 select clause\n", "  * It is also called as row level transformations.\n", "  * Apply standardization rules (convert names and addresses to upper case).\n", "  * Mask partial data (SSN and Date of births).\n", "* Filtering data \u2013 where clause\n", "  * Get orders based on date or product or category.\n", "* Joins \u2013 join (supports outer join as well)\n", "  * Join multiple data sets.\n", "* Aggregations \u2013 group by and aggregations with support of functions such as sum, avg, min, max etc\n", "  * Get revenue for a given order\n", "  * Get revenue for each order\n", "  * Get daily revenue\n", "* Sorting \u2013 order by\n", "  * Sort the final output by date.\n", "  * Sort the final output by date, then by revenue in descending order.\n", "  * Sort the final output by state or province, then by revenue in descending order.\n", "* Analytics Functions \u2013 aggregations, ranking and windowing functions\n", "  * Get top 5 stores by revenue for each state.\n", "  * Get top 5 products by revenue in each category."]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Apache Toree - Scala", "language": "scala", "name": "apache_toree_scala"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.11.12"}}, "nbformat": 4, "nbformat_minor": 4}