{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spark 2\n",
    "\n",
    "Let us go ahead and configure Spark 2 on our single node Hadoop and Spark Cluster. We need to ensure that Spark can run using YARN mode.\n",
    "\n",
    "* Update **/opt/spark2/conf/spark-env.sh** with below environment variables.\n",
    "\n",
    "```shell\n",
    "export HADOOP_HOME=\"/opt/hadoop\"\n",
    "export HADOOP_CONF_DIR=\"/opt/hadoop/etc/hadoop\"\n",
    "export SPARK_DIST_CLASSPATH=$(hadoop --config ${HADOOP_CONF_DIR} classpath)\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/lib/native\n",
    "```\n",
    "\n",
    "* Update **/opt/spark2/conf/spark-defaults.conf** with below properties.\n",
    "\n",
    "```shell\n",
    "spark.driver.extraJavaOptions -Dderby.system.home=/tmp/derby/\n",
    "spark.sql.repl.eagerEval.enabled   true\n",
    "spark.master    yarn\n",
    "spark.eventLog.enabled true\n",
    "spark.eventLog.dir               hdfs:///spark2-logs\n",
    "spark.history.provider            org.apache.spark.deploy.history.FsHistoryProvider\n",
    "spark.history.fs.logDirectory     hdfs:///spark2-logs\n",
    "spark.history.fs.update.interval  10s\n",
    "spark.history.ui.port             18081\n",
    "spark.yarn.historyServer.address localhost:18081\n",
    "spark.yarn.jars hdfs:///spark2-jars/*.jar\n",
    "```\n",
    "\n",
    "* We also need to create directories for logs and jars in HDFS. Also, Spark jars should be copied to HDFS folder provided as part of **spark.yarn.jars**.\n",
    "\n",
    "```shell\n",
    "hdfs dfs -mkdir /spark2-jars\n",
    "hdfs dfs -mkdir /spark2-logs\n",
    "\n",
    "hdfs dfs -put /opt/spark2/jars/* /spark2-jars\n",
    "```\n",
    "\n",
    "* By default we will not be able to access Hive Metastore tables and databases using Spark. We need to perform below steps to integrate Spark with Hive Metastore.\n",
    "  * Create soft link for **hive-site.xml** in Spark conf folder.\n",
    "  * We also need to install latest **Postgres JDBC** jar in Spark jars folder.\n",
    "\n",
    "```shell\n",
    "sudo ln -s /opt/hive/conf/hive-site.xml /opt/spark2/conf/\n",
    "sudo wget https://jdbc.postgresql.org/download/postgresql-42.2.19.jar \\\n",
    "    -O /opt/spark2/jars/postgresql-42.2.19.jar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
